{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FingersCounter\n",
    "\n",
    "CNN multiclass classifier for counting number of fingers shown on one hand. Made with EduNet.\n",
    "\n",
    "By Matas Gumbinas, 2019\n",
    "\n",
    "## Introduction & acknowledgements\n",
    "\n",
    "The sole goal of this work is to demonstrate **EduNet** NN (neural networks) modeling framework [1].  \n",
    "For this task a Kaggle dataset \"Fingers\" by Pavel Koryakin [2] was used. The purpose of this  \n",
    "dataset is to help create an image classifier that would count fingers on a hand from 0 to 5.\n",
    "\n",
    "Results:  \n",
    "During this work, using EduNet API, a Convolution Neural Network was created to be trained on the  \n",
    "given dataset. Afterwards, the trained model was tested using unused part of the dataset meant for   \n",
    "testing the trained models. The trained model reached 100% accuracy with both, training and validation  \n",
    "datasets, while running it on testing data an accuracy of 99.97% was achieved.\n",
    "\n",
    "List of references:  \n",
    "1. EduNet. Numpy based educational neural networks modeling framework - from scratch  \n",
    "(by Matas Gumbinas).  \n",
    "https://github.com/gMatas/edunet\n",
    "2. \"Fingers\" dataset (by Pavel Koryakin).  \n",
    "https://www.kaggle.com/gmatas/account\n",
    "\n",
    "## Starting up\n",
    "\n",
    "First, download EduNet python package from github [1] (v1.3.0-alpha.0 release) to the main  \n",
    "directory (at ```fingers-counter/```). Or run the following git commands from your console/terminal  \n",
    "starting from the main directory: \n",
    "```shell\n",
    "git clone https://github.com/gmatas/edunet\n",
    "cd edunet\n",
    "git checkout v1.3.0-alpha.0\n",
    "cd ..\n",
    "```\n",
    "\n",
    "Next, from the project main directory run the following pip command to install the required python  \n",
    "dependencies for running this notebook:\n",
    "```shell\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "Finaly, before running this notebook, please run the following commands:  \n",
    "```shell\n",
    "cd datasets\n",
    "python fingers.py\n",
    "cd ..\n",
    "```\n",
    "\n",
    "```fingers.py``` script will unzip \"fingers.zip\" file and read its contents to original \"**fingers**\" dataset. Afterwards  \n",
    "it will generate a downsampled version of it to a directory \"**fingers_32x32**\". The following work will be done on  \n",
    "the downsampled dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple, Iterable, Optional\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "assert os.path.isdir('edunet'), 'Can not find directory \"edunet\" in the working directory.'\n",
    "sys.path.append('edunet')\n",
    "import edunet as en\n",
    "\n",
    "from mytools import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINGERS32_PATH = 'datasets\\\\fingers_32x32\\\\'\n",
    "FINGERS32_TRAIN_PATH = os.path.join(FINGERS32_PATH, 'train')\n",
    "FINGERS32_TEST_PATH = os.path.join(FINGERS32_PATH, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset_dataframe_from_path(dirpath: str):\n",
    "    filenames = os.listdir(dirpath)\n",
    "    \n",
    "    i_array = 0\n",
    "    filenames_array = [''] * len(filenames)   \n",
    "    fingercount_array = np.empty([len(filenames)], np.uint8)\n",
    "    handside_array = [''] * len(filenames)\n",
    "    \n",
    "    image_extensions = {'png', 'jpg', 'jpeg'}\n",
    "    \n",
    "    for filename in filenames:\n",
    "        parts = filename.split('.')\n",
    "        if len(parts) < 2:\n",
    "            continue\n",
    "\n",
    "        name = '.'.join(parts[:-1])\n",
    "        ext = parts[-1]\n",
    "        if ext.lower() not in image_extensions:\n",
    "            continue\n",
    "\n",
    "        filename_parts = filename.split('.')\n",
    "        filelabel = filename_parts[0].split('_')[-1]\n",
    "        fingercount = filelabel[:-1]\n",
    "        handside = filelabel[-1]\n",
    "        \n",
    "        filenames_array[i_array] = filename\n",
    "        fingercount_array[i_array] = fingercount\n",
    "        handside_array[i_array] = handside\n",
    "        i_array += 1\n",
    "    \n",
    "    return pd.DataFrame(data={\n",
    "        'Filename': filenames_array[:i_array],\n",
    "        'FingersCount': fingercount_array[:i_array],\n",
    "        'HandSide': handside_array[:i_array]\n",
    "    }) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>FingersCount</th>\n",
       "      <th>HandSide</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00048bba-979b-4f84-b833-5bbbb082b582_0L.png</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>000547a2-d456-4b16-b351-12ca9b40e390_0L.png</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>000cac8e-fcf0-4f8c-bd16-c257d1e6d7a8_2L.png</td>\n",
       "      <td>2</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>000d9961-8136-4dee-9820-86e178777958_0L.png</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0010095b-2e3d-4517-a511-1f688c378f96_5L.png</td>\n",
       "      <td>5</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17995</td>\n",
       "      <td>ffed5de7-577a-49f8-8912-a51ca5ec2ce7_0L.png</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17996</td>\n",
       "      <td>ffef96a9-fe26-4e07-816f-23385af4fbdb_4L.png</td>\n",
       "      <td>4</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17997</td>\n",
       "      <td>fff5517f-6329-4588-b0a7-fa41ca820840_0R.png</td>\n",
       "      <td>0</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17998</td>\n",
       "      <td>fff79b8e-4d29-4cfa-bba8-687ba60f4e98_2L.png</td>\n",
       "      <td>2</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17999</td>\n",
       "      <td>fffaffc3-3fe7-44b6-94a1-3e31852dab77_2L.png</td>\n",
       "      <td>2</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Filename  FingersCount HandSide\n",
       "0      00048bba-979b-4f84-b833-5bbbb082b582_0L.png             0        L\n",
       "1      000547a2-d456-4b16-b351-12ca9b40e390_0L.png             0        L\n",
       "2      000cac8e-fcf0-4f8c-bd16-c257d1e6d7a8_2L.png             2        L\n",
       "3      000d9961-8136-4dee-9820-86e178777958_0L.png             0        L\n",
       "4      0010095b-2e3d-4517-a511-1f688c378f96_5L.png             5        L\n",
       "...                                            ...           ...      ...\n",
       "17995  ffed5de7-577a-49f8-8912-a51ca5ec2ce7_0L.png             0        L\n",
       "17996  ffef96a9-fe26-4e07-816f-23385af4fbdb_4L.png             4        L\n",
       "17997  fff5517f-6329-4588-b0a7-fa41ca820840_0R.png             0        R\n",
       "17998  fff79b8e-4d29-4cfa-bba8-687ba60f4e98_2L.png             2        L\n",
       "17999  fffaffc3-3fe7-44b6-94a1-3e31852dab77_2L.png             2        L\n",
       "\n",
       "[18000 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_df = build_dataset_dataframe_from_path(FINGERS32_TRAIN_PATH)\n",
    "train_dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>FingersCount</th>\n",
       "      <th>HandSide</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>000e7aa6-100b-4c6b-9ff0-e7a8e53e4465_5L.png</td>\n",
       "      <td>5</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>001f6021-8581-4ed2-aed4-cda0af1d5d57_5L.png</td>\n",
       "      <td>5</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0027029b-4c3c-4785-bc1b-b8141331a108_3R.png</td>\n",
       "      <td>3</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>004599fb-c735-4ff3-a969-342dda319382_5L.png</td>\n",
       "      <td>5</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>00500e1a-f4bd-4f66-9eb8-c7fce19a3f6f_5L.png</td>\n",
       "      <td>5</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3595</td>\n",
       "      <td>ff78cf4f-d03c-4b41-9dbc-03bdfdf241bf_2R.png</td>\n",
       "      <td>2</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3596</td>\n",
       "      <td>ff8be861-dd82-4500-893f-e9b6e299c5e1_0L.png</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3597</td>\n",
       "      <td>ff9eeef5-2c62-4bce-9d29-587345a7acfe_4R.png</td>\n",
       "      <td>4</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3598</td>\n",
       "      <td>ffb7e43c-deac-4b8f-83bf-44437104c35d_3R.png</td>\n",
       "      <td>3</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3599</td>\n",
       "      <td>ffb81e76-93e8-4e7f-87cf-7a91a62c8f25_3R.png</td>\n",
       "      <td>3</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3600 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Filename  FingersCount HandSide\n",
       "0     000e7aa6-100b-4c6b-9ff0-e7a8e53e4465_5L.png             5        L\n",
       "1     001f6021-8581-4ed2-aed4-cda0af1d5d57_5L.png             5        L\n",
       "2     0027029b-4c3c-4785-bc1b-b8141331a108_3R.png             3        R\n",
       "3     004599fb-c735-4ff3-a969-342dda319382_5L.png             5        L\n",
       "4     00500e1a-f4bd-4f66-9eb8-c7fce19a3f6f_5L.png             5        L\n",
       "...                                           ...           ...      ...\n",
       "3595  ff78cf4f-d03c-4b41-9dbc-03bdfdf241bf_2R.png             2        R\n",
       "3596  ff8be861-dd82-4500-893f-e9b6e299c5e1_0L.png             0        L\n",
       "3597  ff9eeef5-2c62-4bce-9d29-587345a7acfe_4R.png             4        R\n",
       "3598  ffb7e43c-deac-4b8f-83bf-44437104c35d_3R.png             3        R\n",
       "3599  ffb81e76-93e8-4e7f-87cf-7a91a62c8f25_3R.png             3        R\n",
       "\n",
       "[3600 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset_df = build_dataset_dataframe_from_path(FINGERS32_TEST_PATH)\n",
    "test_dataset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset analysis\n",
    "\n",
    "Dataset grouping by finger count and hand side, to make sure that there would be no biases steming from  \n",
    "unproportionate distribution of classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data preparation & analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>HandSide</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FingersCount</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Filename  HandSide\n",
       "FingersCount                    \n",
       "0                 3000      3000\n",
       "1                 3000      3000\n",
       "2                 3000      3000\n",
       "3                 3000      3000\n",
       "4                 3000      3000\n",
       "5                 3000      3000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_df.groupby('FingersCount').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>FingersCount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HandSide</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>L</td>\n",
       "      <td>9000</td>\n",
       "      <td>9000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>R</td>\n",
       "      <td>9000</td>\n",
       "      <td>9000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Filename  FingersCount\n",
       "HandSide                        \n",
       "L             9000          9000\n",
       "R             9000          9000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_df.groupby('HandSide').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train samples: 17880\n",
      "valid samples: 120\n"
     ]
    }
   ],
   "source": [
    "n_valid_samples = 120\n",
    "seed = 4658976\n",
    "\n",
    "train_df = train_dataset_df.sample(frac=1., random_state=seed)\n",
    "\n",
    "train_df, valid_df = train_test_split(train_df, test_size=120, shuffle=False)\n",
    "\n",
    "print('train samples:', len(train_df))\n",
    "print('valid samples:', len(valid_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>FingersCount</th>\n",
       "      <th>HandSide</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>16990</td>\n",
       "      <td>f1918855-56e0-4a06-ad80-776019d3a3b5_1R.png</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2535</td>\n",
       "      <td>231a27d6-815b-4ce9-a3cd-b04985aff8d7_4L.png</td>\n",
       "      <td>4</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3253</td>\n",
       "      <td>2d100518-91fa-453a-82c2-7345ded50d93_0R.png</td>\n",
       "      <td>0</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7337</td>\n",
       "      <td>6715ac27-1d9b-4c62-92d7-12d88d41fc7c_1R.png</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9465</td>\n",
       "      <td>8598a454-5e1b-4448-88de-00ece2dfd30c_4R.png</td>\n",
       "      <td>4</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4553</td>\n",
       "      <td>3f4f3a88-4fb7-4fbf-b046-ec5fe44330d9_0R.png</td>\n",
       "      <td>0</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10122</td>\n",
       "      <td>8f1de7da-7a18-432d-b78f-ee419bcfff76_3L.png</td>\n",
       "      <td>3</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3701</td>\n",
       "      <td>3378a999-1adb-4711-b1b7-5cfd265b0fd4_4L.png</td>\n",
       "      <td>4</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12412</td>\n",
       "      <td>b0bb0e66-baa8-4c01-9d2a-39bbce812691_0R.png</td>\n",
       "      <td>0</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10827</td>\n",
       "      <td>9982be13-85d3-4111-b7e9-57236e0b7bb9_4R.png</td>\n",
       "      <td>4</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17880 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Filename  FingersCount HandSide\n",
       "16990  f1918855-56e0-4a06-ad80-776019d3a3b5_1R.png             1        R\n",
       "2535   231a27d6-815b-4ce9-a3cd-b04985aff8d7_4L.png             4        L\n",
       "3253   2d100518-91fa-453a-82c2-7345ded50d93_0R.png             0        R\n",
       "7337   6715ac27-1d9b-4c62-92d7-12d88d41fc7c_1R.png             1        R\n",
       "9465   8598a454-5e1b-4448-88de-00ece2dfd30c_4R.png             4        R\n",
       "...                                            ...           ...      ...\n",
       "4553   3f4f3a88-4fb7-4fbf-b046-ec5fe44330d9_0R.png             0        R\n",
       "10122  8f1de7da-7a18-432d-b78f-ee419bcfff76_3L.png             3        L\n",
       "3701   3378a999-1adb-4711-b1b7-5cfd265b0fd4_4L.png             4        L\n",
       "12412  b0bb0e66-baa8-4c01-9d2a-39bbce812691_0R.png             0        R\n",
       "10827  9982be13-85d3-4111-b7e9-57236e0b7bb9_4R.png             4        R\n",
       "\n",
       "[17880 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.FingersCount.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "valid_df.FingersCount.hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing data preparation & analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>HandSide</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FingersCount</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>600</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>600</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>600</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>600</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>600</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>600</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Filename  HandSide\n",
       "FingersCount                    \n",
       "0                  600       600\n",
       "1                  600       600\n",
       "2                  600       600\n",
       "3                  600       600\n",
       "4                  600       600\n",
       "5                  600       600"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset_df.groupby('FingersCount').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>FingersCount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HandSide</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>L</td>\n",
       "      <td>1800</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>R</td>\n",
       "      <td>1800</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Filename  FingersCount\n",
       "HandSide                        \n",
       "L             1800          1800\n",
       "R             1800          1800"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset_df.groupby('HandSide').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset_df.FingersCount.hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FingersCounter model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FingersCounter(object):\n",
    "    \n",
    "    N_CATEGORIES = 6\n",
    "    \n",
    "    def __init__(self, data_size: Iterable[int], labels_size: Iterable[int], dtype: np.dtype, learning_rate: float, random_state=None):\n",
    "        self.__data_size = data_size\n",
    "        self.__labels_size = labels_size\n",
    "        self.__dtype = dtype\n",
    "        self.__learning_rate = 0.01\n",
    "        self.__graph = en.Graph()\n",
    "        self.__ops_map: Dict[str, en.Operation] = dict()\n",
    "        self.__random_state = np.random.RandomState() if random_state is None else random_state\n",
    "        \n",
    "    @classmethod\n",
    "    def load(cls, filepath: str):\n",
    "        with open(filepath, 'rb') as fs:\n",
    "            obj = pickle.load(fs)\n",
    "        \n",
    "        assert isinstance(obj, FingersCounter)\n",
    "        \n",
    "        instance = cls(obj.__data_size, obj.__labels_size, obj.__dtype, obj.__learning_rate, obj.__random_state)\n",
    "        instance.__graph = obj.__graph\n",
    "        instance.__ops_map = obj.__ops_map\n",
    "        return instance\n",
    "        \n",
    "    @property\n",
    "    def graph(self) -> en.Graph:\n",
    "        return self.__graph\n",
    "        \n",
    "    def get_operation_by_name(self, name: str) -> en.Operation:\n",
    "        return self.__ops_map[name]\n",
    "    \n",
    "    def get_operations_names(self) -> List[en.Operation]:\n",
    "        return list(self.__ops_map.keys())\n",
    "    \n",
    "    def drop_operation_by_name(self, name: str):\n",
    "        op = self.__ops_map.pop(name)\n",
    "        self.__graph.remove(op)\n",
    "        return op\n",
    "    \n",
    "    def build(self):\n",
    "        batch_size = self.__data_size[0]\n",
    "        \n",
    "        input_data = en.Input(self.__data_size, self.__dtype)\n",
    "        input_labels = en.Input([batch_size, FingersCounter.N_CATEGORIES, 1], self.__dtype)\n",
    "        \n",
    "        conv_1_1 = en.Convolution2D(input_data, 16, 3, mode='same', weights_initializer=en.initializers.HeNormal, random_state=self.__random_state)\n",
    "        relu_1_1 = en.Relu(conv_1_1)\n",
    "        conv_1_2 = en.Convolution2D(relu_1_1, 16, 3, strides=2, mode='valid', weights_initializer=en.initializers.HeNormal, random_state=self.__random_state)\n",
    "        relu_1_2 = en.Relu(conv_1_2)\n",
    "        \n",
    "        conv_2_1 = en.Convolution2D(relu_1_2, 32, 3, mode='same', weights_initializer=en.initializers.HeNormal, random_state=self.__random_state)\n",
    "        relu_2_1 = en.Relu(conv_2_1)\n",
    "        conv_2_2 = en.Convolution2D(relu_2_1, 32, 3, strides=2, mode='valid', weights_initializer=en.initializers.HeNormal, random_state=self.__random_state)\n",
    "        relu_2_2 = en.Relu(conv_2_2)\n",
    "        \n",
    "        conv_3_1 = en.Convolution2D(relu_2_2, 64, 3, mode='same', weights_initializer=en.initializers.HeNormal, random_state=self.__random_state)\n",
    "        relu_3_1 = en.Relu(conv_3_1)\n",
    "        conv_3_2 = en.Convolution2D(relu_3_1, 64, 3, strides=2, mode='valid', weights_initializer=en.initializers.HeNormal, random_state=self.__random_state)\n",
    "        relu_3_2 = en.Relu(conv_3_2)\n",
    "        \n",
    "        flatten = en.Flatten(relu_3_2)\n",
    "        \n",
    "        dense_1 = en.Dense(flatten, 128, weights_initializer=en.initializers.HeNormal, random_state=self.__random_state)\n",
    "        relu_4 = en.Relu(dense_1)\n",
    "        \n",
    "        dense_2 = en.Dense(relu_4, FingersCounter.N_CATEGORIES, weights_initializer=en.initializers.HeNormal, random_state=self.__random_state)\n",
    "\n",
    "        loss = en.SoftargmaxCrossEntropyWithLogits(input_labels, dense_2)\n",
    "        reduce_sum = en.ReduceSum(loss)\n",
    "        \n",
    "        minimize = en.MomentumOptimizer(self.__learning_rate, gamma=0.9).minimize(reduce_sum)\n",
    "        \n",
    "        self.__ops_map = dict((k, v) for k, v in locals().items() if isinstance(v, en.Operation))\n",
    "        self.__graph.extend(self.__ops_map.values())\n",
    "        \n",
    "    def freeze(self, batch_size: int = 1):\n",
    "        self.__data_size = (batch_size, *data_size[1:])\n",
    "        \n",
    "        input_data = en.Input(self.__data_size, self.__dtype)\n",
    "        \n",
    "        conv_1_1 = en.Convolution2D(input_data, 16, 3, mode='same', random_state=self.__random_state)\n",
    "        relu_1_1 = en.Relu(conv_1_1)\n",
    "        conv_1_2 = en.Convolution2D(relu_1_1, 16, 3, strides=2, mode='valid', random_state=self.__random_state)\n",
    "        relu_1_2 = en.Relu(conv_1_2)\n",
    "        \n",
    "        conv_2_1 = en.Convolution2D(relu_1_2, 32, 3, mode='same', random_state=self.__random_state)\n",
    "        relu_2_1 = en.Relu(conv_2_1)\n",
    "        conv_2_2 = en.Convolution2D(relu_2_1, 32, 3, strides=2, mode='valid', random_state=self.__random_state)\n",
    "        relu_2_2 = en.Relu(conv_2_2)\n",
    "        \n",
    "        conv_3_1 = en.Convolution2D(relu_2_2, 64, 3, mode='same', random_state=self.__random_state)\n",
    "        relu_3_1 = en.Relu(conv_3_1)\n",
    "        conv_3_2 = en.Convolution2D(relu_3_1, 64, 3, strides=2, mode='valid', random_state=self.__random_state)\n",
    "        relu_3_2 = en.Relu(conv_3_2)\n",
    "        \n",
    "        flatten = en.Flatten(relu_3_2)\n",
    "        \n",
    "        dense_1 = en.Dense(flatten, 128, random_state=self.__random_state)\n",
    "        relu_4 = en.Relu(dense_1)\n",
    "        \n",
    "        dense_2 = en.Dense(relu_4, FingersCounter.N_CATEGORIES, random_state=self.__random_state)\n",
    "        softmax = en.SoftArgMax(dense_2, 1)\n",
    "        \n",
    "        # Set trained variables to the newely initialized operations.\n",
    "        conv_1_1.var_list = self.__ops_map['conv_1_1'].var_list\n",
    "        conv_1_2.var_list = self.__ops_map['conv_1_2'].var_list\n",
    "        conv_2_2.var_list = self.__ops_map['conv_2_2'].var_list\n",
    "        conv_3_1.var_list = self.__ops_map['conv_3_1'].var_list\n",
    "        conv_3_2.var_list = self.__ops_map['conv_3_2'].var_list\n",
    "        dense_1.var_list = self.__ops_map['dense_1'].var_list\n",
    "        dense_2.var_list = self.__ops_map['dense_2'].var_list\n",
    "        \n",
    "        # Clear current graph.\n",
    "        for op in self.__graph.get_ops():\n",
    "            self.__graph.remove(op)\n",
    "        del op\n",
    "                \n",
    "        # Fill current graph with new opertions.\n",
    "        self.__ops_map = dict((k, v) for k, v in locals().items() if isinstance(v, en.Operation))\n",
    "        self.__graph.extend(self.__ops_map.values())\n",
    "        \n",
    "    def save(self, filepath: str):\n",
    "        with open(filepath, 'wb') as fs:\n",
    "            pickle.dump(self, fs)\n",
    "            \n",
    "    def read(self, filepath: str):\n",
    "        with open(filepath, 'rb') as fs:\n",
    "            obj = pickle.load(fs)\n",
    "        \n",
    "        assert isinstance(obj, FingersCounter)\n",
    "        \n",
    "        self.__data_size = obj.__data_size\n",
    "        self.__labels_size = obj.__labels_size\n",
    "        self.__dtype = obj.__dtype\n",
    "        self.__learning_rate = obj.__learning_rate\n",
    "        self.__graph = obj.__graph\n",
    "        self.__ops_map = obj.__ops_map\n",
    "        self.__random_state = obj.__random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch_generator(dataset: pd.DataFrame, dataset_path: str, batch_size: int, image_size: Tuple[int, int], is_gray: bool, dtype: np.dtype, n_categories: int):\n",
    "    data_batch = np.empty((batch_size, *image_size, (1 if is_gray else 3)), dtype)\n",
    "    labels_batch = np.empty((batch_size, n_categories, 1), dtype)\n",
    "\n",
    "    current_sample = 0\n",
    "    is_batch_empty = True\n",
    "\n",
    "    for row in dataset.itertuples():\n",
    "        imagepath = os.path.join(dataset_path, row.Filename)\n",
    "        image = cv2.imread(imagepath, (cv2.IMREAD_GRAYSCALE if is_gray else cv2.IMREAD_COLOR))\n",
    "        if image is None:\n",
    "            continue\n",
    "\n",
    "        image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX)\n",
    "        image = np.float32(image) / 255\n",
    "        if is_gray:\n",
    "            data_batch[current_sample] = image[..., None]\n",
    "\n",
    "        label = int(row.FingersCount)\n",
    "        categorical_label = [0 for _ in range(n_categories)]\n",
    "        categorical_label[label] = 1\n",
    "        labels_batch[current_sample, :, 0] = categorical_label\n",
    "\n",
    "        current_sample += 1\n",
    "        is_batch_empty = False\n",
    "\n",
    "        if current_sample % batch_size == 0:\n",
    "            current_sample = 0\n",
    "            is_batch_empty = True\n",
    "            yield data_batch, labels_batch\n",
    "\n",
    "    if not is_batch_empty:\n",
    "        data_batch = data_batch[:current_sample]\n",
    "        labels_batch = labels_batch[:current_sample]\n",
    "        yield data_batch, labels_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FingersCounter classifier training  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    fc: FingersCounter, \n",
    "    train_df: pd.DataFrame, \n",
    "    valid_df: pd.DataFrame, \n",
    "    n_epochs: int, \n",
    "    batch_size: int, \n",
    "    image_size: Tuple[int, int],\n",
    "    is_gray: bool,\n",
    "    dtype: np.dtype,\n",
    "    model_name: str,\n",
    "    model_dirpath: str,\n",
    "    seed=None\n",
    "):    \n",
    "    input_data_op = fc.get_operation_by_name('input_data')\n",
    "    input_labels_op = fc.get_operation_by_name('input_labels')\n",
    "    dense_2_op = fc.get_operation_by_name('dense_2')\n",
    "    loss_op = fc.get_operation_by_name('loss')\n",
    "    minimize_op = fc.get_operation_by_name('minimize')\n",
    "    \n",
    "    flow = en.Flow(fc.graph)\n",
    "    \n",
    "    n_batches = int(math.ceil(len(train_df) / batch_size))\n",
    "    progressbar = ProgressBar(n_batches, name='batch')\n",
    "        \n",
    "    for epoch in range(n_epochs):\n",
    "        is_accum_full = False\n",
    "        accum_counter = 0\n",
    "        accum_size = 500\n",
    "        epoch_loss_accum = [0 for _ in range(accum_size)]\n",
    "        epoch_accuracy_accum = [0 for _ in range(accum_size)]\n",
    "        \n",
    "        \n",
    "        sampled_train_df = train_df.sample(frac=1.0, random_state=seed)\n",
    "        batch_gen = create_batch_generator(sampled_train_df, FINGERS32_TRAIN_PATH, batch_size, image_size, is_gray, dtype, FingersCounter.N_CATEGORIES)\n",
    "        for data_batch, labels_batch in batch_gen:            \n",
    "            input_labels, dense_2, loss, _ = flow.run([input_labels_op, dense_2_op, loss_op, minimize_op], feed_dict={\n",
    "                input_data_op: data_batch,\n",
    "                input_labels_op: labels_batch\n",
    "            })\n",
    "\n",
    "            softmax_output = en.core.math.softargmax(dense_2, 1)\n",
    "\n",
    "            epoch_loss_accum[accum_counter] = np.mean(loss)\n",
    "            epoch_accuracy_accum[accum_counter] = np.equal(np.argmax(softmax_output, axis=1), np.argmax(input_labels, axis=1)).astype(np.float32).mean()\n",
    "            accum_counter += 1\n",
    "\n",
    "            if is_accum_full:\n",
    "                epoch_loss_mean = round(sum(epoch_loss_accum) / accum_size, 4) if accum_size != 0 else 0.\n",
    "                epoch_accuracy_mean = round(sum(epoch_accuracy_accum) / accum_size, 4) if accum_size != 0 else 0.\n",
    "                if accum_counter >= accum_size:\n",
    "                    accum_counter = 0\n",
    "            else:\n",
    "                epoch_loss_mean = round(sum(epoch_loss_accum[:accum_counter]) / accum_counter, 4) if accum_counter != 0 else 0.\n",
    "                epoch_accuracy_mean = round(sum(epoch_accuracy_accum[:accum_counter]) / accum_counter, 4) if accum_counter != 0 else 0.\n",
    "                if accum_counter >= accum_size:\n",
    "                    accum_counter = 0\n",
    "                    is_accum_full = True\n",
    "\n",
    "            epoch_loss_mean = round(sum(epoch_loss_accum[:accum_counter]) / accum_counter, 4) if accum_counter != 0 else 0.\n",
    "            epoch_accuracy_mean = round(sum(epoch_accuracy_accum[:accum_counter]) / accum_counter, 4) if accum_counter != 0 else 0.          \n",
    "            if accum_counter >= accum_size:\n",
    "                accum_counter = 0\n",
    "                is_accum_full = True\n",
    "\n",
    "            progressbar.make_step()\n",
    "            progressbar.printout(\n",
    "                inline=True,\n",
    "                extra='-- loss: {} -- acc: {}'.format(epoch_loss_mean, epoch_accuracy_mean))\n",
    "\n",
    "            \n",
    "        epoch_valid_accum_counter = 0\n",
    "        epoch_valid_loss_accum = 0\n",
    "        epoch_valid_accuracy_accum = 0\n",
    "\n",
    "        batch_gen = create_batch_generator(valid_df, FINGERS32_TRAIN_PATH, batch_size, image_size, is_gray, dtype, FingersCounter.N_CATEGORIES)\n",
    "        for data_batch, labels_batch in batch_gen:            \n",
    "            input_labels, dense_2, loss = flow.run([input_labels_op, dense_2_op, loss_op], feed_dict={\n",
    "                input_data_op: data_batch,\n",
    "                input_labels_op: labels_batch\n",
    "            })\n",
    "            \n",
    "            softmax_output = en.core.math.softargmax(dense_2, 1)\n",
    "\n",
    "            epoch_valid_accum_counter += 1\n",
    "            epoch_valid_loss_accum += np.mean(loss)\n",
    "            epoch_valid_accuracy_accum += np.equal(np.argmax(softmax_output, axis=1), np.argmax(input_labels, axis=1)).astype(np.float32).mean()\n",
    "\n",
    "        epoch_valid_loss_mean = round(epoch_valid_loss_accum / epoch_valid_accum_counter, 4) if epoch_valid_accum_counter != 0 else 0.\n",
    "        epoch_valid_accuracy_mean = round(epoch_valid_accuracy_accum / epoch_valid_accum_counter, 4) if epoch_valid_accum_counter != 0 else 0.\n",
    "\n",
    "        progressbar.printout(\n",
    "            counter=False,\n",
    "            extra='epoch: {} -- train_loss: {} -- train_acc: {} -- valid_loss: {} -- valid_acc: {}'.format(\n",
    "                epoch+1, epoch_loss_mean, epoch_accuracy_mean, epoch_valid_loss_mean, epoch_valid_accuracy_mean))\n",
    "        progressbar.reset()\n",
    "\n",
    "        model_filename = '%s_e%d.%s' % (model_name, epoch+1, 'pkl')\n",
    "        model_savepath = os.path.join(model_dirpath, model_filename)\n",
    "        fc.save(model_savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 60\n",
    "input_size = (32, 32)\n",
    "\n",
    "data_size = (batch_size, *input_size, 1)\n",
    "labels_size = (batch_size, FingersCounter.N_CATEGORIES, 1)\n",
    "input_dtype = np.float32\n",
    "\n",
    "fingerscounter = FingersCounter(data_size, labels_size, input_dtype, learning_rate=0.001)\n",
    "fingerscounter.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_data: (Input)  ..  shape: (60, 32, 32, 1)  .. dtype: float32\n",
      "input_labels: (Input)  ..  shape: (60, 6, 1)  .. dtype: float32\n",
      "conv_1_1: (Convolution2D)  ..  shape: (60, 32, 32, 16)  .. dtype: float32\n",
      "relu_1_1: (Relu)  ..  shape: (60, 32, 32, 16)  .. dtype: float32\n",
      "conv_1_2: (Convolution2D)  ..  shape: (60, 15, 15, 16)  .. dtype: float32\n",
      "relu_1_2: (Relu)  ..  shape: (60, 15, 15, 16)  .. dtype: float32\n",
      "conv_2_1: (Convolution2D)  ..  shape: (60, 15, 15, 32)  .. dtype: float32\n",
      "relu_2_1: (Relu)  ..  shape: (60, 15, 15, 32)  .. dtype: float32\n",
      "conv_2_2: (Convolution2D)  ..  shape: (60, 7, 7, 32)  .. dtype: float32\n",
      "relu_2_2: (Relu)  ..  shape: (60, 7, 7, 32)  .. dtype: float32\n",
      "conv_3_1: (Convolution2D)  ..  shape: (60, 7, 7, 64)  .. dtype: float32\n",
      "relu_3_1: (Relu)  ..  shape: (60, 7, 7, 64)  .. dtype: float32\n",
      "conv_3_2: (Convolution2D)  ..  shape: (60, 3, 3, 64)  .. dtype: float32\n",
      "relu_3_2: (Relu)  ..  shape: (60, 3, 3, 64)  .. dtype: float32\n",
      "flatten: (Flatten)  ..  shape: (60, 576, 1)  .. dtype: float32\n",
      "dense_1: (Dense)  ..  shape: (60, 128, 1)  .. dtype: float32\n",
      "relu_4: (Relu)  ..  shape: (60, 128, 1)  .. dtype: float32\n",
      "dense_2: (Dense)  ..  shape: (60, 6, 1)  .. dtype: float32\n",
      "loss: (None)  ..  shape: (60, 1, 1)  .. dtype: float32\n",
      "reduce_sum: (ReduceSum)  ..  shape: (1, 1, 1)  .. dtype: float32\n",
      "minimize: (Minimizer)  ..  shape: (1, 1, 1)  .. dtype: float32\n"
     ]
    }
   ],
   "source": [
    "for opname in fingerscounter.get_operations_names():\n",
    "    op = fingerscounter.get_operation_by_name(opname)\n",
    "    print('{}: ({})  ..  shape: {}  .. dtype: {}'.format(opname, op.name, op.output.shape, op.output.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[======================>] epoch: 1 -- train_loss: 0.1371 -- train_acc: 0.949 -- valid_loss: 0.0016 -- valid_acc: 1.0\n",
      "[======================>] epoch: 2 -- train_loss: 0.0008 -- train_acc: 0.9999 -- valid_loss: 0.0004 -- valid_acc: 1.0\n",
      "[======================>] epoch: 3 -- train_loss: 0.0001 -- train_acc: 1.0 -- valid_loss: 0.0002 -- valid_acc: 1.0\n",
      "[======================>] epoch: 4 -- train_loss: 0.0001 -- train_acc: 1.0 -- valid_loss: 0.0001 -- valid_acc: 1.0\n",
      "[======================>] epoch: 5 -- train_loss: 0.0001 -- train_acc: 1.0 -- valid_loss: 0.0001 -- valid_acc: 1.0\n",
      "[======================>] epoch: 6 -- train_loss: 0.0 -- train_acc: 1.0 -- valid_loss: 0.0001 -- valid_acc: 1.0\n",
      "[======================>] epoch: 7 -- train_loss: 0.0 -- train_acc: 1.0 -- valid_loss: 0.0001 -- valid_acc: 1.0\n",
      "[======================>] epoch: 8 -- train_loss: 0.0 -- train_acc: 1.0 -- valid_loss: 0.0 -- valid_acc: 1.0\n",
      "[======================>] epoch: 9 -- train_loss: 0.0 -- train_acc: 1.0 -- valid_loss: 0.0 -- valid_acc: 1.0\n",
      "[======================>] epoch: 10 -- train_loss: 0.0 -- train_acc: 1.0 -- valid_loss: 0.0 -- valid_acc: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "model_name = 'fingerscounter'\n",
    "seed = 69696969\n",
    "\n",
    "train(fingerscounter, train_df, valid_df, n_epochs, batch_size, input_size, True, input_dtype, model_name, './', seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FingersCounter classifier testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_data: (Input)  ..  shape: (60, 32, 32, 1)  .. dtype: float32\n",
      "input_labels: (Input)  ..  shape: (60, 6, 1)  .. dtype: float32\n",
      "conv_1_1: (Convolution2D)  ..  shape: (60, 32, 32, 16)  .. dtype: float32\n",
      "relu_1_1: (Relu)  ..  shape: (60, 32, 32, 16)  .. dtype: float32\n",
      "conv_1_2: (Convolution2D)  ..  shape: (60, 15, 15, 16)  .. dtype: float32\n",
      "relu_1_2: (Relu)  ..  shape: (60, 15, 15, 16)  .. dtype: float32\n",
      "conv_2_1: (Convolution2D)  ..  shape: (60, 15, 15, 32)  .. dtype: float32\n",
      "relu_2_1: (Relu)  ..  shape: (60, 15, 15, 32)  .. dtype: float32\n",
      "conv_2_2: (Convolution2D)  ..  shape: (60, 7, 7, 32)  .. dtype: float32\n",
      "relu_2_2: (Relu)  ..  shape: (60, 7, 7, 32)  .. dtype: float32\n",
      "conv_3_1: (Convolution2D)  ..  shape: (60, 7, 7, 64)  .. dtype: float32\n",
      "relu_3_1: (Relu)  ..  shape: (60, 7, 7, 64)  .. dtype: float32\n",
      "conv_3_2: (Convolution2D)  ..  shape: (60, 3, 3, 64)  .. dtype: float32\n",
      "relu_3_2: (Relu)  ..  shape: (60, 3, 3, 64)  .. dtype: float32\n",
      "flatten: (Flatten)  ..  shape: (60, 576, 1)  .. dtype: float32\n",
      "dense_1: (Dense)  ..  shape: (60, 128, 1)  .. dtype: float32\n",
      "relu_4: (Relu)  ..  shape: (60, 128, 1)  .. dtype: float32\n",
      "dense_2: (Dense)  ..  shape: (60, 6, 1)  .. dtype: float32\n",
      "loss: (None)  ..  shape: (60, 1, 1)  .. dtype: float32\n",
      "reduce_sum: (ReduceSum)  ..  shape: (1, 1, 1)  .. dtype: float32\n",
      "minimize: (Minimizer)  ..  shape: (1, 1, 1)  .. dtype: float32\n"
     ]
    }
   ],
   "source": [
    "model_filepath = 'fingerscounter_e1.pkl'\n",
    "fingerscounter = FingersCounter.load(model_filepath)\n",
    "\n",
    "for name in fingerscounter.get_operations_names():\n",
    "    op = fingerscounter.get_operation_by_name(name)\n",
    "    print('{}: ({})  ..  shape: {}  .. dtype: {}'.format(name, op.name, op.output.shape, op.output.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(\n",
    "    fc: FingersCounter, \n",
    "    test_df: pd.DataFrame, \n",
    "    batch_size: int, \n",
    "    image_size: Tuple[int, int],\n",
    "    is_gray: bool,\n",
    "    dtype: np.dtype,\n",
    ") -> Tuple[float, float]:    \n",
    "    input_data_op = fc.get_operation_by_name('input_data')\n",
    "    input_labels_op = fc.get_operation_by_name('input_labels')\n",
    "    dense_2_op = fc.get_operation_by_name('dense_2')\n",
    "    loss_op = fc.get_operation_by_name('loss')\n",
    "    reduce_sum_op = fc.get_operation_by_name('reduce_sum')\n",
    "    \n",
    "    flow = en.Flow(fc.graph)\n",
    "    \n",
    "    n_batches = int(math.ceil(len(test_df) / batch_size))\n",
    "    progressbar = ProgressBar(n_batches, name='batch')\n",
    "        \n",
    "    accum_counter = 0\n",
    "    loss_accum = 0\n",
    "    accuracy_accum = 0\n",
    "    \n",
    "    batch_gen = create_batch_generator(test_df, FINGERS32_TEST_PATH, batch_size, image_size, is_gray, dtype, FingersCounter.N_CATEGORIES)\n",
    "    for data_batch, labels_batch in batch_gen:\n",
    "        input_labels, dense_2, batch_loss = flow.run([input_labels_op, dense_2_op, reduce_sum_op], feed_dict={\n",
    "            input_data_op: data_batch,\n",
    "            input_labels_op: labels_batch\n",
    "        })\n",
    "\n",
    "        softmax_output = en.core.math.softargmax(dense_2, 1)\n",
    "\n",
    "        loss_accum += batch_loss.sum()\n",
    "        accuracy_accum += np.equal(np.argmax(softmax_output, axis=1), np.argmax(input_labels, axis=1)).astype(np.float32).sum()\n",
    "        accum_counter += batch_size\n",
    "\n",
    "        loss_mean = np.round(loss_accum / accum_counter, 5) if accum_counter != 0 else 0.\n",
    "        accuracy_mean = np.round(accuracy_accum / accum_counter, 5) if accum_counter != 0 else 0.\n",
    "\n",
    "        progressbar.make_step()\n",
    "        progressbar.printout(\n",
    "            inline=True,\n",
    "            extra='-- loss: {} -- acc: {}'.format(loss_mean, accuracy_mean))\n",
    "    \n",
    "    progressbar.printout()\n",
    "    return loss_mean, accuracy_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply trained models on training data to select the best one.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model \"fingerscounter_e1.pkl\"...\n",
      "[======================>] batch: 60/60 -- loss: 0.00147 -- acc: 0.99972\n",
      "Running model \"fingerscounter_e2.pkl\"...\n",
      "[======================>] batch: 60/60 -- loss: 0.00129 -- acc: 0.99944\n",
      "Running model \"fingerscounter_e3.pkl\"...\n",
      "[======================>] batch: 60/60 -- loss: 0.00141 -- acc: 0.99944\n",
      "Running model \"fingerscounter_e4.pkl\"...\n",
      "[======================>] batch: 60/60 -- loss: 0.00141 -- acc: 0.99944\n",
      "Running model \"fingerscounter_e5.pkl\"...\n",
      "[======================>] batch: 60/60 -- loss: 0.00135 -- acc: 0.99944\n",
      "Running model \"fingerscounter_e6.pkl\"...\n",
      "[======================>] batch: 60/60 -- loss: 0.00129 -- acc: 0.99944\n",
      "Running model \"fingerscounter_e7.pkl\"...\n",
      "[======================>] batch: 60/60 -- loss: 0.00121 -- acc: 0.99944\n",
      "Running model \"fingerscounter_e8.pkl\"...\n",
      "[======================>] batch: 60/60 -- loss: 0.00115 -- acc: 0.99944\n",
      "Running model \"fingerscounter_e9.pkl\"...\n",
      "[======================>] batch: 60/60 -- loss: 0.0011 -- acc: 0.999444\n",
      "Running model \"fingerscounter_e10.pkl\"...\n",
      "[======================>] batch: 60/60 -- loss: 0.00106 -- acc: 0.99944\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "batch_size = 60\n",
    "input_size = (32, 32)\n",
    "data_size = (batch_size, *input_size, 1)\n",
    "input_dtype = np.float32\n",
    "\n",
    "models_results: Dict[str, Optional[Tuple[float, float]]] = {\n",
    "    'fingerscounter_e1.pkl' : None,\n",
    "    'fingerscounter_e2.pkl' : None,\n",
    "    'fingerscounter_e3.pkl' : None,\n",
    "    'fingerscounter_e4.pkl' : None,\n",
    "    'fingerscounter_e5.pkl' : None,\n",
    "    'fingerscounter_e6.pkl' : None,\n",
    "    'fingerscounter_e7.pkl' : None,\n",
    "    'fingerscounter_e8.pkl' : None,\n",
    "    'fingerscounter_e9.pkl' : None,\n",
    "    'fingerscounter_e10.pkl' : None,\n",
    "}\n",
    "\n",
    "for filepath in models_results.keys():\n",
    "    if not os.path.isfile(filepath):\n",
    "        print('Skipping model \"%s\".' % filepath)\n",
    "        continue\n",
    "    \n",
    "    print('Running model \"%s\"...' % filepath)\n",
    "    models_results[filepath] = test(FingersCounter.load(filepath), test_dataset_df, batch_size, input_size, True, input_dtype)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FingersCounter model selection and post-training configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_data: (Input)  ..  shape: (60, 32, 32, 1)  .. dtype: float32\n",
      "input_labels: (Input)  ..  shape: (60, 6, 1)  .. dtype: float32\n",
      "conv_1_1: (Convolution2D)  ..  shape: (60, 32, 32, 16)  .. dtype: float32\n",
      "relu_1_1: (Relu)  ..  shape: (60, 32, 32, 16)  .. dtype: float32\n",
      "conv_1_2: (Convolution2D)  ..  shape: (60, 15, 15, 16)  .. dtype: float32\n",
      "relu_1_2: (Relu)  ..  shape: (60, 15, 15, 16)  .. dtype: float32\n",
      "conv_2_1: (Convolution2D)  ..  shape: (60, 15, 15, 32)  .. dtype: float32\n",
      "relu_2_1: (Relu)  ..  shape: (60, 15, 15, 32)  .. dtype: float32\n",
      "conv_2_2: (Convolution2D)  ..  shape: (60, 7, 7, 32)  .. dtype: float32\n",
      "relu_2_2: (Relu)  ..  shape: (60, 7, 7, 32)  .. dtype: float32\n",
      "conv_3_1: (Convolution2D)  ..  shape: (60, 7, 7, 64)  .. dtype: float32\n",
      "relu_3_1: (Relu)  ..  shape: (60, 7, 7, 64)  .. dtype: float32\n",
      "conv_3_2: (Convolution2D)  ..  shape: (60, 3, 3, 64)  .. dtype: float32\n",
      "relu_3_2: (Relu)  ..  shape: (60, 3, 3, 64)  .. dtype: float32\n",
      "flatten: (Flatten)  ..  shape: (60, 576, 1)  .. dtype: float32\n",
      "dense_1: (Dense)  ..  shape: (60, 128, 1)  .. dtype: float32\n",
      "relu_4: (Relu)  ..  shape: (60, 128, 1)  .. dtype: float32\n",
      "dense_2: (Dense)  ..  shape: (60, 6, 1)  .. dtype: float32\n",
      "loss: (None)  ..  shape: (60, 1, 1)  .. dtype: float32\n",
      "reduce_sum: (ReduceSum)  ..  shape: (1, 1, 1)  .. dtype: float32\n",
      "minimize: (Minimizer)  ..  shape: (1, 1, 1)  .. dtype: float32\n"
     ]
    }
   ],
   "source": [
    "# Selected model:\n",
    "model_filepath = 'fingerscounter_e1.pkl'\n",
    "fingerscounter = FingersCounter.load(model_filepath)\n",
    "\n",
    "for name in fingerscounter.get_operations_names():\n",
    "    op = fingerscounter.get_operation_by_name(name)\n",
    "    print('{}: ({})  ..  shape: {}  .. dtype: {}'.format(name, op.name, op.output.shape, op.output.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_data: (Input)  ..  shape: (1, 32, 32, 1)  .. dtype: float32\n",
      "conv_1_1: (Convolution2D)  ..  shape: (1, 32, 32, 16)  .. dtype: float32\n",
      "relu_1_1: (Relu)  ..  shape: (1, 32, 32, 16)  .. dtype: float32\n",
      "conv_1_2: (Convolution2D)  ..  shape: (1, 15, 15, 16)  .. dtype: float32\n",
      "relu_1_2: (Relu)  ..  shape: (1, 15, 15, 16)  .. dtype: float32\n",
      "conv_2_1: (Convolution2D)  ..  shape: (1, 15, 15, 32)  .. dtype: float32\n",
      "relu_2_1: (Relu)  ..  shape: (1, 15, 15, 32)  .. dtype: float32\n",
      "conv_2_2: (Convolution2D)  ..  shape: (1, 7, 7, 32)  .. dtype: float32\n",
      "relu_2_2: (Relu)  ..  shape: (1, 7, 7, 32)  .. dtype: float32\n",
      "conv_3_1: (Convolution2D)  ..  shape: (1, 7, 7, 64)  .. dtype: float32\n",
      "relu_3_1: (Relu)  ..  shape: (1, 7, 7, 64)  .. dtype: float32\n",
      "conv_3_2: (Convolution2D)  ..  shape: (1, 3, 3, 64)  .. dtype: float32\n",
      "relu_3_2: (Relu)  ..  shape: (1, 3, 3, 64)  .. dtype: float32\n",
      "flatten: (Flatten)  ..  shape: (1, 576, 1)  .. dtype: float32\n",
      "dense_1: (Dense)  ..  shape: (1, 128, 1)  .. dtype: float32\n",
      "relu_4: (Relu)  ..  shape: (1, 128, 1)  .. dtype: float32\n",
      "dense_2: (Dense)  ..  shape: (1, 6, 1)  .. dtype: float32\n",
      "softmax: (SoftArgMax)  ..  shape: (1, 6, 1)  .. dtype: float32\n",
      "\n",
      "Model is saved to: fingerscounter.pkl\n"
     ]
    }
   ],
   "source": [
    "# Freeze model by removing unnecesary operations from its graph and reset the batch size.\n",
    "fingerscounter.freeze(batch_size=1)\n",
    "\n",
    "# Print out network operations after freezing the model.\n",
    "for name in fingerscounter.get_operations_names():\n",
    "    op = fingerscounter.get_operation_by_name(name)\n",
    "    print('{}: ({})  ..  shape: {}  .. dtype: {}'.format(name, op.name, op.output.shape, op.output.dtype))\n",
    "print()\n",
    "\n",
    "# Save freezed model.\n",
    "model_filepath = 'fingerscounter.pkl'\n",
    "fingerscounter.save(model_filepath)\n",
    "print('Model is saved to:', model_filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
